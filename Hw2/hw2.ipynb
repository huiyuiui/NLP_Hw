{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic as a language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14*(43+20)=</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(6+1)*5=</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13+32+29=</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31*(3-11)=</td>\n",
       "      <td>-248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24*49+1=</td>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           src   tgt\n",
       "0  14*(43+20)=   882\n",
       "1     (6+1)*5=    35\n",
       "2    13+32+29=    74\n",
       "3   31*(3-11)=  -248\n",
       "4     24*49+1=  1177"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./dataset/arithmetic_train.csv')\n",
    "df_eval = pd.read_csv('./dataset/arithmetic_eval.csv')\n",
    "\n",
    "df_train = df_train.drop('hash', axis=1)\n",
    "df_eval = df_eval.drop('hash', axis=1)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14*(43+20)=882</td>\n",
       "      <td>882</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(6+1)*5=35</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13+32+29=74</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31*(3-11)=-248</td>\n",
       "      <td>-248</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24*49+1=1177</td>\n",
       "      <td>1177</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              src   tgt  len\n",
       "0  14*(43+20)=882   882   14\n",
       "1      (6+1)*5=35    35   10\n",
       "2     13+32+29=74    74   11\n",
       "3  31*(3-11)=-248  -248   14\n",
       "4    24*49+1=1177  1177   12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the input data to string\n",
    "df_train['tgt'] = df_train['tgt'].apply(lambda x: str(x))\n",
    "df_train['src'] = df_train['src'].add(df_train['tgt'])\n",
    "df_train['len'] = df_train['src'].apply(lambda x: len(x))\n",
    "\n",
    "df_eval['tgt'] = df_eval['tgt'].apply(lambda x: str(x))\n",
    "df_eval['src'] = df_eval['src'].add(df_eval['tgt'])\n",
    "df_eval['len'] = df_eval['src'].apply(lambda x: len(x))\n",
    "\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dictionary\n",
    "\n",
    "- The model cannot perform calculations directly with plain text.\n",
    "- Convert all text(numbers/symbols) into numerical representations.\n",
    "- Special tokens\n",
    "  - '\\<pad>'\n",
    "    - Each sentence within a batch may have different lengths.\n",
    "    - The length is padded with '<pad>' to match the longest sentence in the batch\n",
    "  - '\\<eos>'\n",
    "     -  Specifies the end of the generated sequence.\n",
    "     -  Without '<eos>', the model will not know when to stop generating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 18\n",
      "char_to_id: {'<pad>': 0, '<eos>': 1, '+': 2, '-': 3, '*': 4, '=': 5, '(': 6, ')': 7, '0': 8, '1': 9, '2': 10, '3': 11, '4': 12, '5': 13, '6': 14, '7': 15, '8': 16, '9': 17}\n",
      "id_to_char {0: '<pad>', 1: '<eos>', 2: '+', 3: '-', 4: '*', 5: '=', 6: '(', 7: ')', 8: '0', 9: '1', 10: '2', 11: '3', 12: '4', 13: '5', 14: '6', 15: '7', 16: '8', 17: '9'}\n"
     ]
    }
   ],
   "source": [
    "# Build a dictionary and give every token in the train dataset an id\n",
    "# The dictionary should contain <eos> and <pad>\n",
    "# char_to_id is to convert charactors to ids, while id_to_char is the opposite\n",
    "char_to_id = {}\n",
    "id_to_char = {}\n",
    "tokens = ['<pad>', '<eos>', '+', '-', '*', '=', '(', ')']\n",
    "\n",
    "for idx, token in enumerate(tokens):\n",
    "    char_to_id[token] = idx\n",
    "    id_to_char[idx] = token\n",
    "\n",
    "for i in range(10):\n",
    "    char_to_id[str(i)] = i + len(tokens)\n",
    "    id_to_char[i + len(tokens)] = str(i)\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "print('Vocab size: {}'.format(vocab_size))\n",
    "print(\"char_to_id:\", char_to_id)\n",
    "print(\"id_to_char\", id_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "- The data is processed into the format required for the model's input and output.\n",
    "- Example\" 1+2+3=0\n",
    "  - Model input: 1 + 2 - 3 = 0\n",
    "  - Model output: / / / / / 0 \\<eos> (the \"/\" can be replaced with \\<pad>)\n",
    "  - The key for the model's output is that the model does not need to predict the next character of the previous part.\n",
    "  - What matters is that once the model sees '=', it should start generating the answer, which is '0'.\n",
    "  - After generating the answer, it should also generate \\<eos>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: 14*(43+20)=882\n",
      "char_id_list: [9, 12, 4, 6, 12, 11, 2, 10, 8, 7, 5, 16, 16, 10] length: 14\n",
      "label_id_list: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 16, 10, 1] length: 14\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "char_id_list = []\n",
    "label_id_list = []\n",
    "\n",
    "for src in df_train['src']:\n",
    "    id_list = []\n",
    "    label_list = []\n",
    "    answer_flag = 0 # record whether '=' appeared\n",
    "    for token in list(src):\n",
    "        id_list.append(char_to_id[token])\n",
    "        if(token == '='): \n",
    "            answer_flag = 1\n",
    "            continue\n",
    "        if(answer_flag): label_list.append(char_to_id[token]) # append answer if '=' appeard\n",
    "        else: label_list.append(char_to_id['<pad>']) # append '<pad>' before '=' \n",
    "    # id_list.append(char_to_id['<eos>'])\n",
    "    label_list.append(char_to_id['<eos>'])\n",
    "    \n",
    "    char_id_list.append(id_list)\n",
    "    label_id_list.append(label_list)\n",
    "    \n",
    "print(\"src:\", df_train['src'][0])\n",
    "print('char_id_list:', char_id_list[0], \"length:\", len(char_id_list[0]))\n",
    "print('label_id_list:', label_id_list[0], \"length:\", len(label_id_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>len</th>\n",
       "      <th>char_id_list</th>\n",
       "      <th>label_id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14*(43+20)=882</td>\n",
       "      <td>882</td>\n",
       "      <td>14</td>\n",
       "      <td>[9, 12, 4, 6, 12, 11, 2, 10, 8, 7, 5, 16, 16, 10]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 16, 10, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(6+1)*5=35</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>[6, 14, 2, 9, 7, 4, 13, 5, 11, 13]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 11, 13, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13+32+29=74</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>[9, 11, 2, 11, 10, 2, 10, 17, 5, 15, 12]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 15, 12, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31*(3-11)=-248</td>\n",
       "      <td>-248</td>\n",
       "      <td>14</td>\n",
       "      <td>[11, 9, 4, 6, 11, 3, 9, 9, 7, 5, 3, 10, 12, 16]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 10, 12, 16, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24*49+1=1177</td>\n",
       "      <td>1177</td>\n",
       "      <td>12</td>\n",
       "      <td>[10, 12, 4, 12, 17, 2, 9, 5, 9, 9, 15, 15]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 9, 9, 15, 15, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              src   tgt  len  \\\n",
       "0  14*(43+20)=882   882   14   \n",
       "1      (6+1)*5=35    35   10   \n",
       "2     13+32+29=74    74   11   \n",
       "3  31*(3-11)=-248  -248   14   \n",
       "4    24*49+1=1177  1177   12   \n",
       "\n",
       "                                        char_id_list  \\\n",
       "0  [9, 12, 4, 6, 12, 11, 2, 10, 8, 7, 5, 16, 16, 10]   \n",
       "1                 [6, 14, 2, 9, 7, 4, 13, 5, 11, 13]   \n",
       "2           [9, 11, 2, 11, 10, 2, 10, 17, 5, 15, 12]   \n",
       "3    [11, 9, 4, 6, 11, 3, 9, 9, 7, 5, 3, 10, 12, 16]   \n",
       "4         [10, 12, 4, 12, 17, 2, 9, 5, 9, 9, 15, 15]   \n",
       "\n",
       "                                   label_id_list  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 16, 10, 1]  \n",
       "1               [0, 0, 0, 0, 0, 0, 0, 11, 13, 1]  \n",
       "2            [0, 0, 0, 0, 0, 0, 0, 0, 15, 12, 1]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 10, 12, 16, 1]  \n",
       "4         [0, 0, 0, 0, 0, 0, 0, 9, 9, 15, 15, 1]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['char_id_list'] = char_id_list\n",
    "df_train['label_id_list'] = label_id_list\n",
    "\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Batching\n",
    "\n",
    "- Use `torch.utils.data.Dataset` to create a data generation tool called dataset.\n",
    "- Then, use `torch.utils.data.DataLoader` to randomly sample from the dataset and group the samples into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        # return how much data in the Dataset object\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Extract the input data x and the ground truth y from the data\n",
    "        x = torch.tensor(self.data['char_id_list'][index], dtype=torch.long)\n",
    "        y = torch.tensor(self.data['label_id_list'][index], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding function\n",
    "# this cell is referenced to Chat-GPT\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    x, y = zip(*batch)\n",
    "    x = pad_sequence(x, batch_first=True, padding_value=char_to_id['<pad>'])\n",
    "    y = pad_sequence(y, batch_first=True, padding_value=char_to_id['<pad>'])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "\n",
    "- The `start_char` is fed into the model.\n",
    "- Each time a sequence is input into the model, it generates a prediction for the next token.\n",
    "- The prediction for the next token corresponds to the last element in the model's output sequence.\n",
    "- When the output is '\\<eos>', the generation should be stopped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(MathRNN, self).__init__()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=vocab_size,\n",
    "                                            embedding_dim=embed_dim,\n",
    "                                            padding_idx=char_to_id['<pad>'])\n",
    "        self.lstm = torch.nn.LSTM(input_size=embed_dim,\n",
    "                                  hidden_size=hidden_dim,\n",
    "                                  batch_first=True)\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=hidden_dim, out_features= hidden_dim // 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=hidden_dim // 2, out_features=vocab_size),\n",
    "            # torch.nn.Softmax(dim=-1) # cross entropy loss will do this by itself\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)\n",
    "        output, hidden = self.lstm(embed) # (batch_size, sequence_length, hidden_dim)\n",
    "        logits = self.linear(output) # (batch_size, sequence_length, vocab_size)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def generator(self, start_char, max_len=200):\n",
    "        char_list = [char_to_id[c] for c in start_char]\n",
    "        \n",
    "        next_char = None\n",
    "        \n",
    "        while len(char_list) < max_len:\n",
    "            # Pack the char_list to tensor\n",
    "            # Input the tensor to the embedding layer, LSTM layers, linear respectively\n",
    "            # write your code here\n",
    "            in_tensor = torch.tensor(char_list).to(device)\n",
    "            \n",
    "            y = self.forward(in_tensor) # Obtain the next token prediction y\n",
    "            \n",
    "            next_char = torch.argmax(y, dim=-1)[-1].item() # Use argmax function to get the next token prediction\n",
    "                    \n",
    "            if next_char == char_to_id['<eos>']: break\n",
    "            \n",
    "            char_list.append(next_char)\n",
    "                \n",
    "        return [id_to_char[ch_id] for ch_id in char_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "embed_dim = 32\n",
    "hidden_dim = 128\n",
    "lr = 1e-4\n",
    "batch_size = 4096\n",
    "\n",
    "dataset = Dataset(df_train)\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "model = MathRNN(vocab_size=vocab_size, embed_dim=embed_dim, hidden_dim=hidden_dim)\n",
    "optimier = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss(ignore_index=char_to_id['<pad>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathRNN(\n",
       "  (embedding): Embedding(18, 32, padding_idx=0)\n",
       "  (lstm): LSTM(32, 128, batch_first=True)\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "store_epoch = 5\n",
    "\n",
    "# load checkpoint\n",
    "model = torch.load('./checkpoints/model_10.pt')\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [03:07<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5692586302757263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [03:09<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5741397142410278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [03:05<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.5830414295196533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [03:05<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.5845175981521606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [03:03<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.5705891251564026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [03:05<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.5755837559700012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [03:03<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.5891082286834717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [03:06<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.5744043588638306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [03:04<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.5860238671302795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 579/579 [03:06<00:00,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.5737103223800659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This cell is referenced to Chat-GPT\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in tqdm(data_loader):\n",
    "        # get data\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        pred = model(x_batch)\n",
    "\n",
    "        # Backward\n",
    "        loss = cross_entropy_loss(pred.view(-1, vocab_size), y_batch.view(-1))\n",
    "        optimier.zero_grad()\n",
    "        loss.backward()\n",
    "        optimier.step()\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "    if((epoch + 1) % store_epoch == 0):\n",
    "        torch.save(model, f'./checkpoints/model_{epoch+1}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store model checkpoint\n",
    "torch.save(model, './checkpoints/model_10.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: 48+43+34=125\n",
      "char_id_list: ['4', '8', '+', '4', '3', '+', '3', '4', '='] length: 9\n",
      "label_id_list: [0, 0, 0, 0, 0, 0, 0, 0, 9, 10, 13] length: 11\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "char_eval_list = []\n",
    "label_id_eval_list = []\n",
    "\n",
    "for src in df_eval['src']:\n",
    "    char_list = []\n",
    "    label_list = []\n",
    "    answer_flag = 0 # record whether '=' appeared\n",
    "    for token in list(src):\n",
    "        if(answer_flag == 0):\n",
    "            char_list.append(token) # append input before '=' (include)\n",
    "        if(token == '='): \n",
    "            answer_flag = 1\n",
    "            continue\n",
    "        if(answer_flag): label_list.append(char_to_id[token]) # append answer if '=' appeard\n",
    "        else: label_list.append(char_to_id['<pad>']) # append '<pad>' before '=' \n",
    "    \n",
    "    char_eval_list.append(char_list)\n",
    "    label_id_eval_list.append(label_list)\n",
    "    \n",
    "print(\"src:\", df_eval['src'][0])\n",
    "print('char_id_list:', char_eval_list[0], \"length:\", len(char_eval_list[0]))\n",
    "print('label_id_list:', label_id_eval_list[0], \"length:\", len(label_id_eval_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "263250it [16:15, 269.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate count: 0 / 263250\n",
      "Evaluate Acc: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "ac_count = 0\n",
    "total_count = len(label_id_eval_list)\n",
    "model.eval()\n",
    "\n",
    "for x, y in tqdm(zip(char_eval_list, label_id_eval_list)):\n",
    "    pred = model.generator(x)\n",
    "    if(len(pred) != len(y)): continue\n",
    "    ac_flag = 1\n",
    "    for idx, label_char in enumerate(y):\n",
    "        if(label_char == char_to_id['<pad>']): continue\n",
    "        else:\n",
    "            if(pred[idx] != label_char):\n",
    "                ac_flag = 0\n",
    "                break\n",
    "    if(ac_flag == 1): ac_count += 1\n",
    "    \n",
    "acc = round(ac_count / total_count, 2)\n",
    "print(f\"Accurate count: {ac_count} / {total_count}\")\n",
    "print(f\"Evaluate Acc: {acc}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
